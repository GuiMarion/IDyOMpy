
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="X-UA-Compatible" content="IE=Edge" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <title>idyom.longTermModel &#8212; IDyOM  documentation</title>
    <link rel="stylesheet" href="../../_static/alabaster.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
    <script type="text/javascript" id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
    <script type="text/javascript" src="../../_static/jquery.js"></script>
    <script type="text/javascript" src="../../_static/underscore.js"></script>
    <script type="text/javascript" src="../../_static/doctools.js"></script>
    <script type="text/javascript" src="../../_static/language_data.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
   
  <link rel="stylesheet" href="../../_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head><body>
  <div class="document">
    
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="../../index.html">IDyOM</a></h1>



<p class="blurb">A Python Implementation of IDyOM</p>




<p>
<iframe src="https://ghbtns.com/github-btn.html?user=GuiMarion&repo=IDyOM&type=watch&count=true&size=large&v=2"
  allowtransparency="true" frameborder="0" scrolling="0" width="200px" height="35px"></iframe>
</p>






<h3><a href="../../index.html">Table of Contents</a></h3>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../index.html">Welcome to IDyOMâ€™s documentation!</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../doc.html">Documentation for the Code</a></li>
</ul>
<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="../../index.html">Documentation overview</a><ul>
  <li><a href="../index.html">Module code</a><ul>
  </ul></li>
  </ul></li>
</ul>
</div>
<div id="searchbox" style="display: none" role="search">
  <h3>Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../../search.html" method="get">
      <input type="text" name="q" />
      <input type="submit" value="Go" />
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
    </div>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>








        </div>
      </div>
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <h1>Source code for idyom.longTermModel</h1><div class="highlight"><pre>
<span></span><span class="kn">from</span> <span class="nn">idyom</span> <span class="k">import</span> <span class="n">data</span>
<span class="kn">from</span> <span class="nn">idyom</span> <span class="k">import</span> <span class="n">markovChain</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pickle</span>
<span class="kn">from</span> <span class="nn">tqdm</span> <span class="k">import</span> <span class="n">tqdm</span>
<span class="kn">import</span> <span class="nn">math</span>

<span class="n">VERBOSE</span> <span class="o">=</span> <span class="kc">False</span>	

<div class="viewcode-block" id="longTermModel"><a class="viewcode-back" href="../../doc.html#idyom.longTermModel.longTermModel">[docs]</a><span class="k">class</span> <span class="nc">longTermModel</span><span class="p">():</span>
	<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">	Module implementing the Long Term Model from IDyOM, this model contains several Markov Chains of different orders weighted by their respective shanon entropy.</span>

<span class="sd">	:param viewPoint: viewPoint to use, cf. data.getViewPoints()</span>
<span class="sd">	:param maxOrder: maximal order of the models</span>
<span class="sd">	:param alphabetSize(optional): size of the alphabet, number of viewPoints value to take account in</span>

<span class="sd">	:type viewPoint: string</span>
<span class="sd">	:type maxOrder: int</span>
<span class="sd">	:type alphabetSize(optional): int</span>
<span class="sd">	&quot;&quot;&quot;</span>

	<span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">viewPoint</span><span class="p">,</span> <span class="n">maxOrder</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">STM</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">init</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>

		<span class="c1"># ViewPoint to use</span>
		<span class="bp">self</span><span class="o">.</span><span class="n">viewPoint</span> <span class="o">=</span> <span class="n">viewPoint</span>

		<span class="c1"># maximum order if given</span>
		<span class="bp">self</span><span class="o">.</span><span class="n">maxOrder</span> <span class="o">=</span> <span class="n">maxOrder</span>

		<span class="c1"># to track if is LTM or STM</span>
		<span class="bp">self</span><span class="o">.</span><span class="n">STM</span> <span class="o">=</span> <span class="n">STM</span>

		<span class="c1"># in order to compute model entropy directly from MC entropies</span>
		<span class="bp">self</span><span class="o">.</span><span class="n">entropies</span> <span class="o">=</span> <span class="p">{}</span>

		<span class="k">if</span> <span class="n">init</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>

			<span class="n">maxOrder</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">init</span><span class="p">)</span>

			<span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">maxOrder</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span> 
				<span class="n">maxOrder</span> <span class="o">=</span> <span class="n">maxOrder</span> <span class="o">//</span> <span class="mi">2</span> <span class="c1"># CHANGE IT TO maxOrder - 1, maybe</span>
			<span class="k">else</span><span class="p">:</span>
				<span class="n">maxOrder</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">maxOrder</span>

			<span class="bp">self</span><span class="o">.</span><span class="n">maxOrder</span> <span class="o">=</span> <span class="n">maxOrder</span>

			<span class="k">if</span> <span class="n">VERBOSE</span><span class="p">:</span>
				<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;The maximal order is:&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">maxOrder</span><span class="p">)</span>

			<span class="c1"># list contening different order markov chains</span>
			<span class="bp">self</span><span class="o">.</span><span class="n">models</span> <span class="o">=</span> <span class="p">[]</span>
			<span class="k">for</span> <span class="n">order</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">maxOrder</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span>
				<span class="bp">self</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">markovChain</span><span class="o">.</span><span class="n">markovChain</span><span class="p">(</span><span class="n">order</span><span class="p">,</span> <span class="n">STM</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">STM</span><span class="p">))</span>

		<span class="bp">self</span><span class="o">.</span><span class="n">benchmark</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>

	<span class="k">def</span> <span class="nf">getObservations</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
		<span class="n">ret</span> <span class="o">=</span> <span class="mi">0</span>
		<span class="k">for</span> <span class="n">model</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">models</span><span class="p">:</span>
			<span class="n">ret</span> <span class="o">+=</span> <span class="n">model</span><span class="o">.</span><span class="n">getObservationsSum</span><span class="p">()</span>
		<span class="k">return</span> <span class="n">ret</span>

<div class="viewcode-block" id="longTermModel.train"><a class="viewcode-back" href="../../doc.html#idyom.longTermModel.longTermModel.train">[docs]</a>	<span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">shortTerm</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
		<span class="sd">&quot;&quot;&quot; </span>
<span class="sd">		Fill the matrix from data</span>
<span class="sd">		</span>
<span class="sd">		:param data: data to train from</span>

<span class="sd">		:type data: list of np.array or list of list of int</span>
<span class="sd">		&quot;&quot;&quot;</span>

		<span class="k">if</span> <span class="n">shortTerm</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
			<span class="c1"># training all the models</span>
			<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">models</span><span class="p">)):</span>
				<span class="bp">self</span><span class="o">.</span><span class="n">models</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">train</span><span class="p">([</span><span class="n">data</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">models</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">order</span><span class="o">-</span><span class="mi">1</span><span class="p">:]])</span>
				<span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">models</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">usedScores</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
					<span class="k">if</span> <span class="n">VERBOSE</span><span class="p">:</span>
						<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;The order is too high for these data, we stop the training here.&quot;</span><span class="p">)</span>
					<span class="k">break</span>
			<span class="k">return</span>

		<span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
			<span class="n">maxOrder</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
			<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">)):</span>
				<span class="n">maxOrder</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="n">i</span><span class="p">]),</span> <span class="n">maxOrder</span><span class="p">)</span>
		<span class="k">else</span><span class="p">:</span>
			<span class="n">maxOrder</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

		<span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">maxOrder</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span> 
			<span class="n">maxOrder</span> <span class="o">=</span> <span class="n">maxOrder</span> <span class="o">//</span> <span class="mi">2</span>
		<span class="k">else</span><span class="p">:</span>
			<span class="n">maxOrder</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">maxOrder</span>

		<span class="bp">self</span><span class="o">.</span><span class="n">maxOrder</span> <span class="o">=</span> <span class="n">maxOrder</span>

		<span class="k">if</span> <span class="n">VERBOSE</span><span class="p">:</span>
			<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;The maximal order is:&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">maxOrder</span><span class="p">)</span>

		<span class="c1"># list contening different order markov chains</span>
		<span class="bp">self</span><span class="o">.</span><span class="n">models</span> <span class="o">=</span> <span class="p">[]</span>
		<span class="k">for</span> <span class="n">order</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">maxOrder</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span>
			<span class="bp">self</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">markovChain</span><span class="o">.</span><span class="n">markovChain</span><span class="p">(</span><span class="n">order</span><span class="p">,</span> <span class="n">STM</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">STM</span><span class="p">))</span>


		<span class="c1"># training all the models</span>
		<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">models</span><span class="p">)):</span>
			<span class="bp">self</span><span class="o">.</span><span class="n">models</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
			<span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">models</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">usedScores</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
				<span class="k">if</span> <span class="n">VERBOSE</span><span class="p">:</span>
					<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;The order is too high for these data, we stop the training here.&quot;</span><span class="p">)</span>
				<span class="k">break</span></div>

<div class="viewcode-block" id="longTermModel.getPrediction"><a class="viewcode-back" href="../../doc.html#idyom.longTermModel.longTermModel.getPrediction">[docs]</a>	<span class="k">def</span> <span class="nf">getPrediction</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sequence</span><span class="p">):</span>
		<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">		Returns the probability distribution from a given state</span>
<span class="sd">		</span>
<span class="sd">		:param sequence: a sequence of viewPoint data, cf. data.getData(viewPoint)</span>

<span class="sd">		:type sequence: np.array(length)</span>

<span class="sd">		:return: dictionary | dico[z] = P(z|sequence) (float)</span>
<span class="sd">		&quot;&quot;&quot;</span>

		<span class="n">alphabet</span> <span class="o">=</span> <span class="p">[]</span>
		<span class="k">for</span> <span class="n">model</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">models</span><span class="p">:</span>
			<span class="n">alphabet</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">alphabet</span><span class="p">)</span>

		<span class="n">alphabet</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">alphabet</span><span class="p">))</span>
		<span class="n">alphabet</span><span class="o">.</span><span class="n">sort</span><span class="p">()</span>

		<span class="n">dico</span> <span class="o">=</span> <span class="p">{}</span>

		<span class="k">for</span> <span class="n">z</span> <span class="ow">in</span> <span class="n">alphabet</span><span class="p">:</span>
			<span class="n">dico</span><span class="p">[</span><span class="nb">str</span><span class="p">(</span><span class="n">z</span><span class="p">)]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">getLikelihood</span><span class="p">(</span><span class="n">sequence</span><span class="p">,</span> <span class="n">z</span><span class="p">)</span>

		<span class="k">return</span> <span class="n">dico</span></div>

<div class="viewcode-block" id="longTermModel.getEntropyMax"><a class="viewcode-back" href="../../doc.html#idyom.longTermModel.longTermModel.getEntropyMax">[docs]</a>	<span class="k">def</span> <span class="nf">getEntropyMax</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">):</span>
		<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">		Return the maximum entropy for an alphabet. This is the case where all element is equiprobable.</span>

<span class="sd">		:param state: state to compute from</span>
<span class="sd">		:type state: list or str(list)</span>

<span class="sd">		:return: maxEntropy (float)	</span>
<span class="sd">		&quot;&quot;&quot;</span>

		<span class="n">alphabetSize</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">count_nonzero</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">getPrediction</span><span class="p">(</span><span class="n">state</span><span class="p">)</span><span class="o">.</span><span class="n">values</span><span class="p">()))</span>

		<span class="n">maxEntropy</span> <span class="o">=</span> <span class="mi">0</span>

		<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">alphabetSize</span><span class="p">):</span>
			<span class="n">maxEntropy</span> <span class="o">-=</span> <span class="p">(</span><span class="mi">1</span><span class="o">/</span><span class="n">alphabetSize</span><span class="p">)</span> <span class="o">*</span> <span class="n">math</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">1</span><span class="o">/</span><span class="n">alphabetSize</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>

		<span class="k">return</span> <span class="n">maxEntropy</span></div>

	<span class="k">def</span> <span class="nf">getAlphabet</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
		<span class="n">alphabet</span> <span class="o">=</span> <span class="p">[]</span>
		<span class="k">for</span> <span class="n">model</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">models</span><span class="p">:</span>
			<span class="n">alphabet</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">alphabet</span><span class="p">)</span>

		<span class="k">return</span> <span class="nb">list</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">alphabet</span><span class="p">))</span>

<div class="viewcode-block" id="longTermModel.getEntropy"><a class="viewcode-back" href="../../doc.html#idyom.longTermModel.longTermModel.getEntropy">[docs]</a>	<span class="k">def</span> <span class="nf">getEntropy</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">):</span>
		<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">		Return shanon entropy of the distribution of the model from a given state</span>

<span class="sd">		:param state: state to compute from</span>
<span class="sd">		:type state: list or str(list)</span>

<span class="sd">		:return: entropy (float)</span>
<span class="sd">		&quot;&quot;&quot;</span>
		<span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">mergeProbas</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">entropies</span><span class="p">[</span><span class="nb">str</span><span class="p">(</span><span class="n">state</span><span class="p">)],</span> <span class="bp">self</span><span class="o">.</span><span class="n">entropies</span><span class="p">[</span><span class="nb">str</span><span class="p">(</span><span class="n">state</span><span class="p">)])</span> </div>
		<span class="c1"># P = self.getPrediction(state).values()</span>

		<span class="c1"># if None in P:</span>
		<span class="c1"># 	print(&quot;It&#39;s not possible to compute this entropy, we kill the execution.&quot;)</span>
		<span class="c1"># 	print(&quot;state:&quot;,state)</span>
		<span class="c1"># 	print(&quot;probabilities:&quot;, P)</span>
		<span class="c1"># 	quit()</span>

		<span class="c1"># entropy = 0</span>

		<span class="c1"># for p in P:</span>
		<span class="c1"># 	if p != 0:</span>
		<span class="c1"># 		entropy -= p * math.log(p, 2)</span>

		<span class="c1"># state = str(state)</span>
		<span class="c1"># weights = self.entropies[state]</span>
		<span class="c1"># # we inverse the entropies</span>
		<span class="c1"># weights = (weights.astype(float)+np.finfo(float).eps)**(-1)</span>
		
		<span class="c1"># # Doomy normalization</span>
		<span class="c1"># for w in weights:</span>
		<span class="c1"># 	if w &lt; 0:</span>
		<span class="c1"># 		weights += abs(min(weights))</span>
		<span class="c1"># 		break</span>
		<span class="c1"># if np.sum(weights) == 0:</span>
		<span class="c1"># 	weights = np.ones(len(weights))</span>

		<span class="c1"># weights = weights/np.sum(weights)</span>


		<span class="c1"># disjoint =self.mergeProbas(self.entropies[state], self.entropies[state]) - np.sum(weights*np.log2(weights))</span>

		<span class="c1"># newEntropy = self.mergeProbas(self.entropies[state], self.entropies[state]) + disjoint*0.0</span>

		<span class="c1"># self.benchmark[0] += (entropy - newEntropy)**2</span>
		<span class="c1"># self.benchmark[1] += 1</span>
		<span class="c1"># self.benchmark[2] += entropy</span>

		<span class="c1"># return newEntropy</span>

<div class="viewcode-block" id="longTermModel.getRelativeEntropy"><a class="viewcode-back" href="../../doc.html#idyom.longTermModel.longTermModel.getRelativeEntropy">[docs]</a>	<span class="k">def</span> <span class="nf">getRelativeEntropy</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">):</span>
		<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">		Return the relative entropy H(m)/Hmax(m). It is used for weighting the merging of models without bein affected by the alphabet size.</span>

<span class="sd">		:param state: state to compute from</span>
<span class="sd">		:type state: list or str(list)</span>

<span class="sd">		:return: entropy (float)		</span>
<span class="sd">		&quot;&quot;&quot;</span>

		<span class="n">maxEntropy</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">getEntropyMax</span><span class="p">(</span><span class="n">state</span><span class="p">)</span>

		<span class="k">if</span> <span class="n">maxEntropy</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
			<span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">getEntropy</span><span class="p">(</span><span class="n">state</span><span class="p">)</span><span class="o">/</span><span class="n">maxEntropy</span>
		<span class="k">else</span><span class="p">:</span>
			<span class="k">return</span> <span class="mi">1</span></div>



<div class="viewcode-block" id="longTermModel.getLikelihood"><a class="viewcode-back" href="../../doc.html#idyom.longTermModel.longTermModel.getLikelihood">[docs]</a>	<span class="k">def</span> <span class="nf">getLikelihood</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">note</span><span class="p">):</span>
		<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">		Returns the likelihood of a note given a state</span>
<span class="sd">		</span>
<span class="sd">		:param state: a sequence of viewPoint data, cf. data.getData(viewPoint)</span>
<span class="sd">		:param note: the interger or name of the note</span>

<span class="sd">		:type state: np.array(length)</span>
<span class="sd">		:type note:	int or string</span>

<span class="sd">		:return: float value of the likelihood</span>
<span class="sd">		&quot;&quot;&quot;</span>
		<span class="n">probas</span> <span class="o">=</span> <span class="p">[]</span>
		<span class="n">weights</span> <span class="o">=</span> <span class="p">[]</span>
		<span class="n">observations</span> <span class="o">=</span> <span class="p">[]</span>

		<span class="n">k</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
		<span class="k">for</span> <span class="n">model</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">models</span><span class="p">:</span>
			<span class="n">k</span> <span class="o">+=</span> <span class="mi">1</span>
			<span class="k">if</span> <span class="nb">str</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">state</span><span class="p">[</span><span class="o">-</span><span class="n">model</span><span class="o">.</span><span class="n">order</span><span class="p">:]))</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">probabilities</span><span class="p">:</span>
				<span class="k">if</span> <span class="nb">abs</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">probabilities</span><span class="p">[</span><span class="nb">str</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">state</span><span class="p">[</span><span class="o">-</span><span class="n">model</span><span class="o">.</span><span class="n">order</span><span class="p">:]))]</span><span class="o">.</span><span class="n">values</span><span class="p">()))</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mf">0.001</span><span class="p">:</span>
					<span class="nb">print</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="s2">&quot;do not sum to 1 ...&quot;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">probabilities</span><span class="p">[</span><span class="nb">str</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">state</span><span class="p">[</span><span class="o">-</span><span class="n">model</span><span class="o">.</span><span class="n">order</span><span class="p">:]))]</span><span class="o">.</span><span class="n">values</span><span class="p">())))</span>
			<span class="c1"># we don&#39;t want to take in account a model that is not capable of prediction</span>
			<span class="k">if</span> <span class="n">model</span><span class="o">.</span><span class="n">order</span> <span class="o">&lt;=</span> <span class="nb">len</span><span class="p">(</span><span class="n">state</span><span class="p">)</span> <span class="ow">and</span> <span class="n">model</span><span class="o">.</span><span class="n">getLikelihood</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">state</span><span class="p">[</span><span class="o">-</span><span class="n">model</span><span class="o">.</span><span class="n">order</span><span class="p">:])),</span> <span class="n">note</span><span class="p">)</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
				<span class="k">if</span> <span class="n">model</span><span class="o">.</span><span class="n">getObservations</span><span class="p">(</span><span class="n">state</span><span class="p">[</span><span class="o">-</span><span class="n">model</span><span class="o">.</span><span class="n">order</span><span class="p">:])</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span> 		
					<span class="n">probas</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">getLikelihood</span><span class="p">(</span><span class="n">state</span><span class="p">[</span><span class="o">-</span><span class="n">model</span><span class="o">.</span><span class="n">order</span><span class="p">:],</span> <span class="n">note</span><span class="p">))</span>
					<span class="n">weights</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">getRelativeEntropy</span><span class="p">(</span><span class="n">state</span><span class="p">[</span><span class="o">-</span><span class="n">model</span><span class="o">.</span><span class="n">order</span><span class="p">:]))</span>
					<span class="n">observations</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">getObservations</span><span class="p">(</span><span class="n">state</span><span class="p">[</span><span class="o">-</span><span class="n">model</span><span class="o">.</span><span class="n">order</span><span class="p">:]))</span>

		<span class="k">if</span> <span class="n">probas</span> <span class="o">==</span> <span class="p">[]</span> <span class="ow">and</span> <span class="kc">False</span><span class="p">:</span>
			<span class="nb">print</span><span class="p">(</span><span class="n">state</span><span class="p">)</span>
			<span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">state</span><span class="p">))</span>
			<span class="nb">print</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">getLikelihood</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">state</span><span class="p">[</span><span class="o">-</span><span class="n">model</span><span class="o">.</span><span class="n">order</span><span class="p">:])),</span> <span class="n">note</span><span class="p">)</span> <span class="p">)</span>
			<span class="nb">print</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">order</span><span class="p">)</span>
			<span class="nb">print</span><span class="p">()</span>

		<span class="k">if</span> <span class="n">probas</span> <span class="o">==</span> <span class="p">[]:</span>
			<span class="k">return</span> <span class="kc">None</span>

		<span class="k">if</span> <span class="kc">False</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">mergeProbas</span><span class="p">(</span><span class="n">probas</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">weights</span><span class="p">))</span> <span class="o">&lt;</span> <span class="mf">0.00001</span><span class="p">:</span>
			<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;probas:&quot;</span><span class="p">,</span> <span class="n">probas</span><span class="p">)</span>
			<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;weights:&quot;</span><span class="p">,</span> <span class="n">weights</span><span class="p">)</span>
			<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;note:&quot;</span><span class="p">,</span> <span class="n">note</span><span class="p">)</span>
			<span class="nb">print</span><span class="p">()</span>

		<span class="bp">self</span><span class="o">.</span><span class="n">entropies</span><span class="p">[</span><span class="nb">str</span><span class="p">(</span><span class="n">state</span><span class="p">)]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">weights</span><span class="p">)</span>

		<span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">mergeProbas</span><span class="p">(</span><span class="n">probas</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">weights</span><span class="p">))</span></div>

<div class="viewcode-block" id="longTermModel.mergeProbas"><a class="viewcode-back" href="../../doc.html#idyom.longTermModel.longTermModel.mergeProbas">[docs]</a>	<span class="k">def</span> <span class="nf">mergeProbas</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">probas</span><span class="p">,</span> <span class="n">weights</span><span class="p">,</span> <span class="n">b</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
		<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">		Merging probabilities from different orders, for now we use arithmetic mean</span>

<span class="sd">		:param probas: probabilities to merge</span>
<span class="sd">		:param weights: weights for the mean, should be get from normalized entropy</span>

<span class="sd">		:type probas: list or numpy array</span>
<span class="sd">		:type weights: list or numpy array</span>

<span class="sd">		:return: merged probabilities (float)</span>
<span class="sd">		&quot;&quot;&quot;</span>

		<span class="c1"># we inverse the entropies</span>
		<span class="n">weights</span> <span class="o">=</span> <span class="p">(</span><span class="n">weights</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">float</span><span class="p">)</span><span class="o">+</span><span class="n">np</span><span class="o">.</span><span class="n">finfo</span><span class="p">(</span><span class="nb">float</span><span class="p">)</span><span class="o">.</span><span class="n">eps</span><span class="p">)</span><span class="o">**</span><span class="p">(</span><span class="o">-</span><span class="n">b</span><span class="p">)</span>
		
		<span class="c1"># Doomy normalization</span>
		<span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">weights</span><span class="p">:</span>
			<span class="k">if</span> <span class="n">w</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
				<span class="n">weights</span> <span class="o">+=</span> <span class="nb">abs</span><span class="p">(</span><span class="nb">min</span><span class="p">(</span><span class="n">weights</span><span class="p">))</span>
				<span class="k">break</span>
		<span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">weights</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
			<span class="n">weights</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">weights</span><span class="p">))</span>

		<span class="n">weights</span> <span class="o">=</span> <span class="n">weights</span><span class="o">/</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">weights</span><span class="p">)</span>

		<span class="n">ret</span> <span class="o">=</span> <span class="mi">0</span>
		<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">probas</span><span class="p">)):</span>
			<span class="n">ret</span> <span class="o">+=</span> <span class="n">probas</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">*</span><span class="n">weights</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>

		<span class="k">return</span> <span class="n">ret</span></div>



<div class="viewcode-block" id="longTermModel.sample"><a class="viewcode-back" href="../../doc.html#idyom.longTermModel.longTermModel.sample">[docs]</a>	<span class="k">def</span> <span class="nf">sample</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">):</span>
		<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">		Return a element sampled from the model given the sequence S</span>

<span class="sd">		:param S: sequence to sample from</span>

<span class="sd">		:type S: list of integers</span>

<span class="sd">		:return: sampled element (int)</span>
<span class="sd">		&quot;&quot;&quot;</span>


		<span class="n">alphabet</span> <span class="o">=</span> <span class="p">[]</span>
		<span class="k">for</span> <span class="n">model</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">models</span><span class="p">:</span>
			<span class="n">alphabet</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">alphabet</span><span class="p">)</span>

		<span class="n">alphabet</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">alphabet</span><span class="p">))</span>
		<span class="n">alphabet</span><span class="o">.</span><span class="n">sort</span><span class="p">()</span>

		<span class="n">distribution</span> <span class="o">=</span> <span class="p">[]</span>
		<span class="c1"># We reconstruct the distribution according to the sorting of the alphabet</span>
		<span class="k">for</span> <span class="n">elem</span> <span class="ow">in</span> <span class="n">alphabet</span><span class="p">:</span>
			<span class="n">distribution</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">getLikelihood</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="n">elem</span><span class="p">))</span>

		<span class="c1">#print(state)</span>
		<span class="c1">#print(np.sum(distribution))</span>

		<span class="n">ret</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">alphabet</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="n">distribution</span><span class="p">))</span>

		<span class="k">return</span> <span class="n">ret</span></div>

<div class="viewcode-block" id="longTermModel.generate"><a class="viewcode-back" href="../../doc.html#idyom.longTermModel.longTermModel.generate">[docs]</a>	<span class="k">def</span> <span class="nf">generate</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">length</span><span class="p">):</span>
		<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">		Implement a very easy random walk in order to generate a sequence</span>

<span class="sd">		:param length: length of the generated sequence (in elements, not beat so it depends on the quantization)</span>
<span class="sd">		:type length: int</span>

<span class="sd">		:return: sequence (np.array()) </span>
<span class="sd">		&quot;&quot;&quot;</span>

		<span class="n">S</span> <span class="o">=</span> <span class="p">[]</span>
		<span class="c1"># We uniformly choose the first element</span>
		<span class="n">S</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">models</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">alphabet</span><span class="p">)))</span>

		<span class="k">while</span> <span class="nb">len</span><span class="p">(</span><span class="n">S</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">length</span> <span class="ow">and</span> <span class="nb">str</span><span class="p">([</span><span class="n">S</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]])</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">models</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">stateAlphabet</span> <span class="p">:</span>

			<span class="n">S</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">S</span><span class="p">))</span>

		<span class="k">return</span> <span class="n">S</span></div>

<div class="viewcode-block" id="longTermModel.save"><a class="viewcode-back" href="../../doc.html#idyom.longTermModel.longTermModel.save">[docs]</a>	<span class="k">def</span> <span class="nf">save</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">file</span><span class="p">):</span>
		<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">		Save a trained model</span>
<span class="sd">		</span>
<span class="sd">		:param file: path to the file</span>
<span class="sd">		:type file: string</span>
<span class="sd">		&quot;&quot;&quot;</span>

		<span class="n">f</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="n">file</span><span class="p">,</span> <span class="s1">&#39;wb&#39;</span><span class="p">)</span>
		<span class="n">pickle</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="p">,</span> <span class="n">f</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
		<span class="n">f</span><span class="o">.</span><span class="n">close</span><span class="p">()</span></div>

<div class="viewcode-block" id="longTermModel.load"><a class="viewcode-back" href="../../doc.html#idyom.longTermModel.longTermModel.load">[docs]</a>	<span class="k">def</span> <span class="nf">load</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">path</span><span class="p">):</span>
		<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">		Load a trained model</span>

<span class="sd">		:param path: path to the file</span>
<span class="sd">		:type path: string</span>
<span class="sd">		&quot;&quot;&quot;</span>

		<span class="n">f</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="s1">&#39;rb&#39;</span><span class="p">)</span>
		<span class="n">tmp_dict</span> <span class="o">=</span> <span class="n">pickle</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
		<span class="n">f</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>          

		<span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">tmp_dict</span><span class="p">)</span> </div></div>

</pre></div>

          </div>
          
        </div>
      </div>
    <div class="clearer"></div>
  </div>
    <div class="footer">
      &copy;2019, Guilhem Marion.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 1.8.4</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.12</a>
      
    </div>

    

    
  </body>
</html>