
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="X-UA-Compatible" content="IE=Edge" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <title>idyom.markovChain &#8212; IDyOM  documentation</title>
    <link rel="stylesheet" href="../../_static/alabaster.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
    <script type="text/javascript" id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
    <script type="text/javascript" src="../../_static/jquery.js"></script>
    <script type="text/javascript" src="../../_static/underscore.js"></script>
    <script type="text/javascript" src="../../_static/doctools.js"></script>
    <script type="text/javascript" src="../../_static/language_data.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
   
  <link rel="stylesheet" href="../../_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head><body>
  <div class="document">
    
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="../../index.html">IDyOM</a></h1>



<p class="blurb">A Python Implementation of IDyOM</p>




<p>
<iframe src="https://ghbtns.com/github-btn.html?user=GuiMarion&repo=IDyOM&type=watch&count=true&size=large&v=2"
  allowtransparency="true" frameborder="0" scrolling="0" width="200px" height="35px"></iframe>
</p>






<h3><a href="../../index.html">Table of Contents</a></h3>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../index.html">Welcome to IDyOMâ€™s documentation!</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../doc.html">Documentation for the Code</a></li>
</ul>
<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="../../index.html">Documentation overview</a><ul>
  <li><a href="../index.html">Module code</a><ul>
  </ul></li>
  </ul></li>
</ul>
</div>
<div id="searchbox" style="display: none" role="search">
  <h3>Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../../search.html" method="get">
      <input type="text" name="q" />
      <input type="submit" value="Go" />
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
    </div>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>








        </div>
      </div>
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <h1>Source code for idyom.markovChain</h1><div class="highlight"><pre>
<span></span><span class="kn">from</span> <span class="nn">idyom</span> <span class="k">import</span> <span class="n">data</span>
<span class="kn">from</span> <span class="nn">idyom</span> <span class="k">import</span> <span class="n">score</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pickle</span>
<span class="kn">from</span> <span class="nn">tqdm</span> <span class="k">import</span> <span class="n">tqdm</span>
<span class="kn">import</span> <span class="nn">ast</span>
<span class="kn">import</span> <span class="nn">math</span>
<span class="kn">import</span> <span class="nn">warnings</span>

<span class="n">THRESHOLD</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">DEBUG</span> <span class="o">=</span> <span class="kc">False</span>

<span class="c1"># We store state transition for now, mostly for debug reasons</span>
<span class="c1"># at some point, we will be able to only store state to notes transitions</span>
<span class="c1"># this can faster the training part and the storage</span>
<span class="c1"># And also improve efficiency and we will be able to train on more data</span>
<span class="c1"># We are removing this part, we commented the relative code with the flag &lt;states rm&gt; </span>

<div class="viewcode-block" id="markovChain"><a class="viewcode-back" href="../../doc.html#idyom.markovChain.markovChain">[docs]</a><span class="k">class</span> <span class="nc">markovChain</span><span class="p">():</span>
	<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">	Module defining MarkovChain model and usefull functions for the project</span>

<span class="sd">	:param alphabetSize: number of elements in the alphabet</span>
<span class="sd">	:param VERBOSE: print some strange behoviors, for example if asking for unknwown states</span>

<span class="sd">	:type order: int</span>
<span class="sd">	:type VERBOSE: bool</span>
<span class="sd">	&quot;&quot;&quot;</span>
	<span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">order</span><span class="p">,</span> <span class="n">depth</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">VERBOSE</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">STM</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>

		<span class="c1"># order of the model</span>
		<span class="bp">self</span><span class="o">.</span><span class="n">order</span> <span class="o">=</span> <span class="n">order</span>

		<span class="c1"># depth of the model</span>
		<span class="bp">self</span><span class="o">.</span><span class="n">depth</span> <span class="o">=</span> <span class="n">depth</span>

		<span class="c1"># dictionary containing the transition probabilities between states</span>
		<span class="c1"># &lt;states rm&gt; self.transitions = {}</span>

		<span class="c1"># dictionary containing containing the probabilities bewteen states and notes</span>
		<span class="bp">self</span><span class="o">.</span><span class="n">probabilities</span> <span class="o">=</span> <span class="p">{}</span>

		<span class="c1"># store the number of occurences of the probabilities</span>
		<span class="bp">self</span><span class="o">.</span><span class="n">observationsProbas</span> <span class="o">=</span> <span class="p">{}</span>

		<span class="c1"># store the number of occurences of the transitions</span>
		<span class="c1"># &lt;states rm&gt; self.observationsTransitions= {}</span>

		<span class="c1"># alphabet of state of the data</span>
		<span class="bp">self</span><span class="o">.</span><span class="n">stateAlphabet</span> <span class="o">=</span> <span class="p">[]</span>

		<span class="c1"># alphabet of notes of the data</span>
		<span class="bp">self</span><span class="o">.</span><span class="n">alphabet</span> <span class="o">=</span> <span class="p">[]</span>

		<span class="bp">self</span><span class="o">.</span><span class="n">VERBOSE</span> <span class="o">=</span> <span class="n">VERBOSE</span>

		<span class="c1"># In order to store entropy</span>
		<span class="bp">self</span><span class="o">.</span><span class="n">entropies</span> <span class="o">=</span> <span class="p">{}</span>

		<span class="c1"># For tracking</span>
		<span class="bp">self</span><span class="o">.</span><span class="n">STM</span> <span class="o">=</span> <span class="n">STM</span>

		<span class="c1"># We store the number of observation for every state</span>
		<span class="bp">self</span><span class="o">.</span><span class="n">SUM</span> <span class="o">=</span> <span class="p">{}</span>

		<span class="k">if</span> <span class="n">order</span> <span class="o">&lt;</span> <span class="mi">1</span><span class="p">:</span>
			<span class="k">raise</span><span class="p">(</span><span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;order should be at least grater than 1.&quot;</span><span class="p">))</span>

	<span class="k">def</span> <span class="nf">__eq__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">other</span><span class="p">):</span> 
		<span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">other</span><span class="p">,</span> <span class="n">markovChain</span><span class="p">):</span>
			<span class="c1"># don&#39;t attempt to compare against unrelated types</span>
			<span class="k">return</span> <span class="bp">NotImplemented</span>

		<span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">order</span> <span class="o">==</span> <span class="n">other</span><span class="o">.</span><span class="n">order</span> <span class="p">:</span>
			<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Different orders&quot;</span><span class="p">)</span>

		<span class="k">elif</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">depth</span> <span class="o">==</span> <span class="n">other</span><span class="o">.</span><span class="n">depth</span><span class="p">:</span>
			<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Different Depth&quot;</span><span class="p">)</span>

		<span class="k">elif</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">SUM</span> <span class="o">==</span> <span class="n">other</span><span class="o">.</span><span class="n">SUM</span><span class="p">:</span>
			<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Different SUM&quot;</span><span class="p">)</span>

		<span class="k">elif</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">alphabet</span> <span class="o">==</span> <span class="n">other</span><span class="o">.</span><span class="n">alphabet</span><span class="p">:</span>
			<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Different alphabet&quot;</span><span class="p">)</span>

		<span class="k">elif</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">probabilities</span> <span class="o">==</span> <span class="n">other</span><span class="o">.</span><span class="n">probabilities</span><span class="p">:</span>
			<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Different probabilities&quot;</span><span class="p">)</span>

		<span class="k">elif</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">stateAlphabet</span> <span class="o">==</span> <span class="n">other</span><span class="o">.</span><span class="n">stateAlphabet</span><span class="p">:</span>
			<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Different stateAlphabet&quot;</span><span class="p">)</span>
			
		<span class="k">elif</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">STM</span> <span class="o">==</span> <span class="n">other</span><span class="o">.</span><span class="n">STM</span><span class="p">:</span>
			<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Different STM&quot;</span><span class="p">)</span>

		<span class="c1">#elif not self.entropies == other.entropies:</span>
		<span class="c1">#	print(&quot;Different entropies&quot;)</span>

		<span class="k">else</span><span class="p">:</span>
			<span class="k">return</span> <span class="kc">True</span>

		<span class="k">return</span> <span class="kc">False</span>


<div class="viewcode-block" id="markovChain.train"><a class="viewcode-back" href="../../doc.html#idyom.markovChain.markovChain.train">[docs]</a>	<span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dataset</span><span class="p">,</span> <span class="n">reverse</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
		<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">		Fill the matrix from data, len(data) should be greater than the order.</span>
<span class="sd">		</span>
<span class="sd">		:param data: pre-processed data to train with</span>
<span class="sd">		:type data: data object or list of int</span>
<span class="sd">		&quot;&quot;&quot;</span>

		<span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="nb">list</span><span class="p">)</span> <span class="p">:</span>
			<span class="n">dataset</span> <span class="o">=</span> <span class="p">[</span><span class="n">dataset</span><span class="p">]</span>

		<span class="bp">self</span><span class="o">.</span><span class="n">usedScores</span> <span class="o">=</span> <span class="mi">0</span>

		<span class="k">for</span> <span class="n">data</span> <span class="ow">in</span> <span class="n">dataset</span><span class="p">:</span>
			<span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">)</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">order</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">depth</span> <span class="o">+</span><span class="mi">1</span><span class="p">:</span>
				<span class="c1">#warnings.warn(&quot;We cannot train a model with less data than the order of the model, so we skip this data.&quot;)</span>
				<span class="k">pass</span>
			<span class="k">else</span><span class="p">:</span>
				<span class="bp">self</span><span class="o">.</span><span class="n">usedScores</span> <span class="o">+=</span> <span class="mi">1</span>
				<span class="c1"># iterating over data</span>
				<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">)</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">order</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">depth</span><span class="p">):</span>
					<span class="c1"># case of the reverse prediction, we take a state get the probability to come back to the current state</span>
					<span class="k">if</span> <span class="n">reverse</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
						<span class="n">state</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="bp">self</span><span class="o">.</span><span class="n">order</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">depth</span> <span class="p">:</span> <span class="n">i</span><span class="o">+</span><span class="bp">self</span><span class="o">.</span><span class="n">order</span><span class="o">*</span><span class="mi">2</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">depth</span><span class="p">]))</span>
						<span class="c1"># &lt;states rm&gt; target = str(list(data[i:i+self.order]))</span>
						<span class="n">target_elem</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">i</span><span class="o">+</span><span class="bp">self</span><span class="o">.</span><span class="n">order</span><span class="p">])[</span><span class="mi">0</span><span class="p">])</span>

					<span class="k">else</span><span class="p">:</span>
						<span class="n">state</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">i</span><span class="o">+</span><span class="bp">self</span><span class="o">.</span><span class="n">order</span><span class="p">]))</span>
						<span class="c1"># &lt;states rm&gt; target = str(list(data[i+self.order + self.depth : i+self.order*2 + self.depth]))</span>
						<span class="n">target_elem</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="bp">self</span><span class="o">.</span><span class="n">order</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">depth</span> <span class="p">:</span> <span class="n">i</span><span class="o">+</span><span class="bp">self</span><span class="o">.</span><span class="n">order</span><span class="o">*</span><span class="mi">2</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">depth</span><span class="p">])[</span><span class="mi">0</span><span class="p">])</span>

					<span class="c1"># constructing alphabet</span>
					<span class="k">if</span> <span class="n">state</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">probabilities</span><span class="p">:</span>
						<span class="bp">self</span><span class="o">.</span><span class="n">stateAlphabet</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">state</span><span class="p">)</span>
						<span class="bp">self</span><span class="o">.</span><span class="n">SUM</span><span class="p">[</span><span class="n">state</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
						<span class="c1"># &lt;states rm&gt; self.transitions[state] = {}</span>
						<span class="bp">self</span><span class="o">.</span><span class="n">probabilities</span><span class="p">[</span><span class="n">state</span><span class="p">]</span> <span class="o">=</span> <span class="p">{}</span>
						<span class="bp">self</span><span class="o">.</span><span class="n">observationsProbas</span><span class="p">[</span><span class="n">state</span><span class="p">]</span> <span class="o">=</span> <span class="p">{}</span>
						<span class="c1"># &lt;states rm&gt; self.observationsTransitions[state] = {}</span>

					<span class="k">if</span> <span class="n">target_elem</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">alphabet</span><span class="p">:</span>
						<span class="bp">self</span><span class="o">.</span><span class="n">alphabet</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">target_elem</span><span class="p">)</span>

					<span class="c1"># constructing state transitions</span>
					<span class="c1"># &lt;states rm&gt; if target not in self.observationsTransitions[state]:</span>
					<span class="c1"># &lt;states rm&gt; 	self.observationsTransitions[state][target] = 1</span>
					<span class="c1"># &lt;states rm&gt; else:</span>
					<span class="c1"># &lt;states rm&gt; 	self.observationsTransitions[state][target] += 1</span>

					<span class="c1"># constructing state to note transitions</span>
					<span class="k">if</span> <span class="n">target_elem</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">observationsProbas</span><span class="p">[</span><span class="n">state</span><span class="p">]:</span>
						<span class="bp">self</span><span class="o">.</span><span class="n">observationsProbas</span><span class="p">[</span><span class="n">state</span><span class="p">][</span><span class="n">target_elem</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
					<span class="k">else</span><span class="p">:</span>
						<span class="bp">self</span><span class="o">.</span><span class="n">observationsProbas</span><span class="p">[</span><span class="n">state</span><span class="p">][</span><span class="n">target_elem</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>

					<span class="bp">self</span><span class="o">.</span><span class="n">SUM</span><span class="p">[</span><span class="n">state</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>

		<span class="c1"># We delete states that have less than THRESHOLD occurences</span>
		<span class="k">if</span> <span class="kc">False</span> <span class="ow">and</span> <span class="n">THRESHOLD</span> <span class="ow">is</span> <span class="ow">not</span> <span class="mi">0</span><span class="p">:</span>
			<span class="k">for</span> <span class="n">state</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">SUM</span><span class="p">:</span>
				<span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">SUM</span><span class="p">[</span><span class="n">state</span><span class="p">]</span> <span class="o">&lt;</span> <span class="n">THRESHOLD</span><span class="p">:</span>
					<span class="bp">self</span><span class="o">.</span><span class="n">stateAlphabet</span><span class="o">.</span><span class="n">remove</span><span class="p">(</span><span class="n">state</span><span class="p">)</span>
					<span class="c1"># &lt;states rm&gt; if state in self.transitions:</span>
					<span class="c1"># &lt;states rm&gt; 	self.observationsTransitions.pop(state)</span>
					<span class="k">if</span> <span class="n">state</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">probabilities</span><span class="p">:</span>
						<span class="bp">self</span><span class="o">.</span><span class="n">observationsProbas</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="n">state</span><span class="p">)</span>

		<span class="c1"># We devide by the number of occurence for each state</span>
		<span class="c1"># &lt;states rm&gt; for state in self.transitions:</span>
		<span class="c1"># &lt;states rm&gt; 	for target in self.transitions[state]:</span>
		<span class="c1"># &lt;states rm&gt; 		self.transitions[state][target] = self.observationsTransitions[state][target] / self.SUM[state]</span>

		<span class="k">for</span> <span class="n">state</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">observationsProbas</span><span class="p">:</span>
			<span class="k">for</span> <span class="n">target</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">observationsProbas</span><span class="p">[</span><span class="n">state</span><span class="p">]:</span>
				<span class="bp">self</span><span class="o">.</span><span class="n">probabilities</span><span class="p">[</span><span class="n">state</span><span class="p">][</span><span class="n">target</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">observationsProbas</span><span class="p">[</span><span class="n">state</span><span class="p">][</span><span class="n">target</span><span class="p">]</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">SUM</span><span class="p">[</span><span class="n">state</span><span class="p">]</span>

		<span class="c1"># We sort the alphabet</span>
		<span class="bp">self</span><span class="o">.</span><span class="n">alphabet</span><span class="o">.</span><span class="n">sort</span><span class="p">()</span>
		<span class="bp">self</span><span class="o">.</span><span class="n">stateAlphabet</span><span class="o">.</span><span class="n">sort</span><span class="p">()</span>


		<span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">STM</span> <span class="ow">is</span> <span class="kc">False</span><span class="p">:</span>
			<span class="k">for</span> <span class="n">state</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">stateAlphabet</span><span class="p">:</span>
				<span class="bp">self</span><span class="o">.</span><span class="n">getEntropy</span><span class="p">(</span><span class="n">state</span><span class="p">)</span></div>

<div class="viewcode-block" id="markovChain.getPrediction"><a class="viewcode-back" href="../../doc.html#idyom.markovChain.markovChain.getPrediction">[docs]</a>	<span class="k">def</span> <span class="nf">getPrediction</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">):</span>
		<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">		Return the probability distribution of notes from a given state</span>
<span class="sd">		</span>
<span class="sd">		:param state: a sequence of viewPoints such as len(state) = order</span>
<span class="sd">		:type state: str(np.array(order))</span>

<span class="sd">		:return: dictionary | dico[note] = P(note|state)</span>
<span class="sd">	</span>
<span class="sd">		&quot;&quot;&quot;</span>

		<span class="c1"># return a row in the matrix</span>


		<span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
			<span class="n">state</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">state</span><span class="p">))</span>

		<span class="k">if</span> <span class="n">state</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">probabilities</span><span class="p">:</span>
			<span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">probabilities</span><span class="p">[</span><span class="n">state</span><span class="p">]</span>
		<span class="k">else</span><span class="p">:</span>

			<span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">VERBOSE</span><span class="p">:</span>
				<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;We never saw this state in database&quot;</span><span class="p">)</span>
			
			<span class="n">dico</span> <span class="o">=</span> <span class="p">{}</span>
			<span class="c1"># if we never saw the state, all letter are equilikely</span>
			<span class="k">for</span> <span class="n">z</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">alphabet</span><span class="p">:</span>
				<span class="n">dico</span><span class="p">[</span><span class="n">z</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">alphabet</span><span class="p">)</span>

			<span class="k">return</span> <span class="n">dico</span></div>

<div class="viewcode-block" id="markovChain.getLikelihood"><a class="viewcode-back" href="../../doc.html#idyom.markovChain.markovChain.getLikelihood">[docs]</a>	<span class="k">def</span> <span class="nf">getLikelihood</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">note</span><span class="p">):</span>
		<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">		Return the likelihood of a note given a state</span>
<span class="sd">		</span>
<span class="sd">		:param state: a sequence of viewPoints such as len(state) = order</span>
<span class="sd">		:param note: integer corresponding to the element</span>

<span class="sd">		:type state: np.array(order)</span>
<span class="sd">		:type note: int</span>

<span class="sd">		:return: float value of the likelihood</span>
<span class="sd">		&quot;&quot;&quot;</span>

		<span class="c1"># in order to work with numpy array and list</span>
		<span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
			<span class="n">state</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">state</span><span class="p">))</span>

		<span class="k">if</span> <span class="n">state</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">probabilities</span><span class="p">:</span>
			<span class="k">pass</span>
		<span class="k">else</span><span class="p">:</span>
			<span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">VERBOSE</span><span class="p">:</span>
				<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;We never saw this state in database.&quot;</span><span class="p">)</span>
			<span class="c1"># as we never saw this state in the database, every note is equiprobable</span>
			<span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">alphabet</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
				<span class="k">return</span> <span class="mi">1</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">alphabet</span><span class="p">)</span>
			<span class="k">else</span><span class="p">:</span>
				<span class="k">return</span> <span class="kc">None</span>

		<span class="k">if</span> <span class="nb">str</span><span class="p">(</span><span class="n">note</span><span class="p">)</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">probabilities</span><span class="p">[</span><span class="n">state</span><span class="p">]:</span>
			<span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">probabilities</span><span class="p">[</span><span class="n">state</span><span class="p">][</span><span class="nb">str</span><span class="p">(</span><span class="n">note</span><span class="p">)]</span>
		<span class="k">else</span><span class="p">:</span>
			<span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">VERBOSE</span><span class="p">:</span>
				<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;We never saw this transition in database.&quot;</span><span class="p">)</span>

			<span class="k">if</span> <span class="kc">False</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">order</span> <span class="o">==</span> <span class="mi">1</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">STM</span> <span class="ow">is</span> <span class="kc">False</span><span class="p">:</span>
				<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Short Term?&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">STM</span><span class="p">)</span>
				<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;note:&quot;</span><span class="p">,</span> <span class="n">note</span><span class="p">)</span>
				<span class="nb">print</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">probabilities</span><span class="p">[</span><span class="n">state</span><span class="p">])</span>
				<span class="nb">print</span><span class="p">()</span>
				<span class="nb">print</span><span class="p">()</span>

			<span class="k">return</span> <span class="mf">0.0</span></div>

<div class="viewcode-block" id="markovChain.getEntropyMax"><a class="viewcode-back" href="../../doc.html#idyom.markovChain.markovChain.getEntropyMax">[docs]</a>	<span class="k">def</span> <span class="nf">getEntropyMax</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">):</span>
		<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">		Return the maximum entropy for an alphabet. This is the case where all element is equiprobable.</span>

<span class="sd">		:param state: state to compute from</span>
<span class="sd">		:type state: list or str(list)</span>

<span class="sd">		:return: maxEntropy (float)	</span>
<span class="sd">		&quot;&quot;&quot;</span>

		<span class="n">alphabetSize</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">getPrediction</span><span class="p">(</span><span class="n">state</span><span class="p">)</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>

		<span class="n">maxEntropy</span> <span class="o">=</span> <span class="mi">0</span>

		<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">alphabetSize</span><span class="p">):</span>
			<span class="n">maxEntropy</span> <span class="o">-=</span> <span class="p">(</span><span class="mi">1</span><span class="o">/</span><span class="n">alphabetSize</span><span class="p">)</span> <span class="o">*</span> <span class="n">math</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">1</span><span class="o">/</span><span class="n">alphabetSize</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>

		<span class="k">return</span> <span class="n">maxEntropy</span></div>


	<span class="k">def</span> <span class="nf">getObservationsSum</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>

		<span class="n">ret</span> <span class="o">=</span> <span class="mi">0</span>
		<span class="k">for</span> <span class="n">state</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">SUM</span><span class="p">:</span>
			<span class="n">ret</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">SUM</span><span class="p">[</span><span class="n">state</span><span class="p">]</span>

		<span class="k">return</span> <span class="n">ret</span>

<div class="viewcode-block" id="markovChain.getEntropy"><a class="viewcode-back" href="../../doc.html#idyom.markovChain.markovChain.getEntropy">[docs]</a>	<span class="k">def</span> <span class="nf">getEntropy</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">):</span>
		<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">		Return shanon entropy of the distribution of the model from a given state</span>

<span class="sd">		:param state: state to compute from</span>
<span class="sd">		:type state: list or str(list)</span>

<span class="sd">		:return: entropy (float)</span>
<span class="sd">		&quot;&quot;&quot;</span>

		<span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">STM</span> <span class="ow">and</span> <span class="nb">str</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">state</span><span class="p">))</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">entropies</span><span class="p">:</span>
			<span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">entropies</span><span class="p">[</span><span class="nb">str</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">state</span><span class="p">))]</span>

		<span class="c1"># in order to work with numpy array and list</span>
		<span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
			<span class="n">state</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">state</span><span class="p">))</span>

		<span class="c1"># if the state was never seen, the entropy is the maximal entropy for |alphabet|</span>
		<span class="k">if</span> <span class="n">state</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">probabilities</span> <span class="ow">or</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">getPrediction</span><span class="p">(</span><span class="n">state</span><span class="p">))</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
			<span class="k">return</span> <span class="o">-</span><span class="n">math</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">1</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">alphabet</span><span class="p">))</span>

		<span class="n">P</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">getPrediction</span><span class="p">(</span><span class="n">state</span><span class="p">)</span><span class="o">.</span><span class="n">values</span><span class="p">()</span>

		<span class="n">entropy</span> <span class="o">=</span> <span class="mi">0</span>

		<span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">P</span><span class="p">:</span>
			<span class="n">entropy</span> <span class="o">-=</span> <span class="n">p</span> <span class="o">*</span> <span class="n">math</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>

		<span class="bp">self</span><span class="o">.</span><span class="n">entropies</span><span class="p">[</span><span class="n">state</span><span class="p">]</span> <span class="o">=</span> <span class="n">entropy</span>

		<span class="k">return</span> <span class="n">entropy</span></div>

	<span class="k">def</span> <span class="nf">getObservations</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">):</span>

		<span class="k">if</span> <span class="nb">str</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">state</span><span class="p">))</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">SUM</span><span class="p">:</span>
			<span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">SUM</span><span class="p">[</span><span class="nb">str</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">state</span><span class="p">))]</span>
		<span class="k">else</span><span class="p">:</span>
			<span class="k">return</span> <span class="kc">None</span>

<div class="viewcode-block" id="markovChain.getRelativeEntropy"><a class="viewcode-back" href="../../doc.html#idyom.markovChain.markovChain.getRelativeEntropy">[docs]</a>	<span class="k">def</span> <span class="nf">getRelativeEntropy</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">):</span>
		<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">		Return the relative entropy H(m)/Hmax(m). It is used for weighting the merging of models without bein affected by the alphabet size.</span>

<span class="sd">		:param state: state to compute from</span>
<span class="sd">		:type state: list or str(list)</span>

<span class="sd">		:return: entropy (float)		</span>
<span class="sd">		&quot;&quot;&quot;</span>

		<span class="n">maxEntropy</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">getEntropyMax</span><span class="p">(</span><span class="n">state</span><span class="p">)</span>

		<span class="k">if</span> <span class="n">maxEntropy</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
			<span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">getEntropy</span><span class="p">(</span><span class="n">state</span><span class="p">)</span><span class="o">/</span><span class="n">maxEntropy</span>

		<span class="k">else</span><span class="p">:</span>
			<span class="k">return</span> <span class="mi">1</span></div>


<div class="viewcode-block" id="markovChain.save"><a class="viewcode-back" href="../../doc.html#idyom.markovChain.markovChain.save">[docs]</a>	<span class="k">def</span> <span class="nf">save</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">file</span><span class="p">):</span>
		<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">		Save a trained model</span>
<span class="sd">		</span>
<span class="sd">		:param file: path to the file</span>
<span class="sd">		:type file: string</span>
<span class="sd">		&quot;&quot;&quot;</span>

		<span class="n">f</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="n">file</span><span class="p">,</span> <span class="s1">&#39;wb&#39;</span><span class="p">)</span>
		<span class="n">pickle</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="p">,</span> <span class="n">f</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
		<span class="n">f</span><span class="o">.</span><span class="n">close</span><span class="p">()</span></div>

<div class="viewcode-block" id="markovChain.load"><a class="viewcode-back" href="../../doc.html#idyom.markovChain.markovChain.load">[docs]</a>	<span class="k">def</span> <span class="nf">load</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">path</span><span class="p">):</span>
		<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">		Load a trained model</span>

<span class="sd">		:param path: path to the file</span>
<span class="sd">		:type path: string</span>
<span class="sd">		&quot;&quot;&quot;</span>

		<span class="n">f</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="s1">&#39;rb&#39;</span><span class="p">)</span>
		<span class="n">tmp_dict</span> <span class="o">=</span> <span class="n">pickle</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
		<span class="n">f</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>          

		<span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">tmp_dict</span><span class="p">)</span> </div>


<div class="viewcode-block" id="markovChain.getStatesMatrix"><a class="viewcode-back" href="../../doc.html#idyom.markovChain.markovChain.getStatesMatrix">[docs]</a>	<span class="k">def</span> <span class="nf">getStatesMatrix</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
		<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">		Return the transition matrix between states made from the dictionnary</span>

<span class="sd">		:return: transition matrix (np.array())</span>
<span class="sd">		&quot;&quot;&quot;</span>



		<span class="n">matrix</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">stateAlphabet</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">stateAlphabet</span><span class="p">)))</span>
		<span class="n">k1</span> <span class="o">=</span> <span class="mi">0</span>
		<span class="n">k2</span> <span class="o">=</span> <span class="mi">0</span>

		<span class="k">for</span> <span class="n">state</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">stateAlphabet</span><span class="p">:</span>
			<span class="n">k2</span> <span class="o">=</span> <span class="mi">0</span>
			<span class="k">for</span> <span class="n">target</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">stateAlphabet</span><span class="p">:</span>
				<span class="k">if</span> <span class="n">state</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">probabilities</span> <span class="ow">and</span> <span class="n">target</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">probabilities</span><span class="p">[</span><span class="n">state</span><span class="p">]:</span>
					<span class="n">matrix</span><span class="p">[</span><span class="n">k1</span><span class="p">][</span><span class="n">k2</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">probabilities</span><span class="p">[</span><span class="n">state</span><span class="p">][</span><span class="n">target</span><span class="p">]</span>
				<span class="k">else</span><span class="p">:</span>
					<span class="n">matrix</span><span class="p">[</span><span class="n">k1</span><span class="p">][</span><span class="n">k2</span><span class="p">]</span> <span class="o">=</span> <span class="mf">0.0</span>
					
				<span class="n">k2</span> <span class="o">+=</span> <span class="mi">1</span>
			<span class="n">k1</span> <span class="o">+=</span> <span class="mi">1</span>

		<span class="k">return</span> <span class="n">matrix</span></div>


<div class="viewcode-block" id="markovChain.getMatrix"><a class="viewcode-back" href="../../doc.html#idyom.markovChain.markovChain.getMatrix">[docs]</a>	<span class="k">def</span> <span class="nf">getMatrix</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
		<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">		Return the transition matrix between states and notes</span>

<span class="sd">		:return: transition matrix (np.array())</span>
<span class="sd">		&quot;&quot;&quot;</span>

		<span class="n">matrix</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">stateAlphabet</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">alphabet</span><span class="p">)))</span>
		<span class="n">k1</span> <span class="o">=</span> <span class="mi">0</span>
		<span class="n">k2</span> <span class="o">=</span> <span class="mi">0</span>

		<span class="k">for</span> <span class="n">state</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">stateAlphabet</span><span class="p">:</span>
			<span class="n">k2</span> <span class="o">=</span> <span class="mi">0</span>
			<span class="k">for</span> <span class="n">target</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">alphabet</span><span class="p">:</span>
				<span class="k">if</span> <span class="n">state</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">probabilities</span> <span class="ow">and</span> <span class="n">target</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">probabilities</span><span class="p">[</span><span class="n">state</span><span class="p">]:</span>
					<span class="n">matrix</span><span class="p">[</span><span class="n">k1</span><span class="p">][</span><span class="n">k2</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">probabilities</span><span class="p">[</span><span class="n">state</span><span class="p">][</span><span class="n">target</span><span class="p">]</span>
				<span class="k">else</span><span class="p">:</span>
					<span class="n">matrix</span><span class="p">[</span><span class="n">k1</span><span class="p">][</span><span class="n">k2</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
				<span class="n">k2</span> <span class="o">+=</span> <span class="mi">1</span>
			<span class="n">k1</span> <span class="o">+=</span> <span class="mi">1</span>

		<span class="k">return</span> <span class="n">matrix</span></div>

<div class="viewcode-block" id="markovChain.sample"><a class="viewcode-back" href="../../doc.html#idyom.markovChain.markovChain.sample">[docs]</a>	<span class="k">def</span> <span class="nf">sample</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">S</span><span class="p">):</span>
		<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">		Return a element sampled from the model given the sequence S</span>

<span class="sd">		:param S: sequence to sample from</span>

<span class="sd">		:type S: list of integers</span>

<span class="sd">		:return: sampled element (int)</span>
<span class="sd">		&quot;&quot;&quot;</span>

		<span class="n">state</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">S</span><span class="p">[</span><span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">order</span><span class="p">:]))</span>

		<span class="k">if</span> <span class="n">DEBUG</span><span class="p">:</span>
			<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;state:&quot;</span><span class="p">,</span> <span class="n">state</span><span class="p">)</span>
			<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;sequence:&quot;</span><span class="p">,</span> <span class="n">S</span><span class="p">)</span>

		<span class="n">distribution</span> <span class="o">=</span> <span class="p">[]</span>
		<span class="c1"># We reconstruct the distribution according to the sorting of the alphabet</span>
		<span class="k">for</span> <span class="n">elem</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">alphabet</span><span class="p">:</span>
			<span class="n">distribution</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">getLikelihood</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="n">elem</span><span class="p">))</span>

		<span class="n">ret</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">alphabet</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="n">distribution</span><span class="p">))</span>

		<span class="k">return</span> <span class="n">ret</span></div>

<div class="viewcode-block" id="markovChain.generate"><a class="viewcode-back" href="../../doc.html#idyom.markovChain.markovChain.generate">[docs]</a>	<span class="k">def</span> <span class="nf">generate</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">length</span><span class="p">):</span>
		<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">		Implement a very easy random walk in order to generate a sequence</span>

<span class="sd">		:param length: length of the generated sequence (in elements, not beat so it depends on the quantization)</span>
<span class="sd">		:type length: int</span>

<span class="sd">		:return: sequence (score object) </span>
<span class="sd">		&quot;&quot;&quot;</span>

		<span class="n">S</span> <span class="o">=</span> <span class="p">[]</span>
		<span class="c1"># We uniformly choose the first element</span>
		<span class="n">S</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">ast</span><span class="o">.</span><span class="n">literal_eval</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">stateAlphabet</span><span class="p">)))</span>

		<span class="k">while</span> <span class="nb">len</span><span class="p">(</span><span class="n">S</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">length</span> <span class="ow">and</span> <span class="nb">str</span><span class="p">(</span><span class="n">S</span><span class="p">[</span><span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">order</span><span class="p">:])</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">stateAlphabet</span><span class="p">:</span>

			<span class="n">S</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">S</span><span class="p">))</span>

		<span class="k">return</span> <span class="n">score</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">S</span><span class="p">)</span></div></div>

</pre></div>

          </div>
          
        </div>
      </div>
    <div class="clearer"></div>
  </div>
    <div class="footer">
      &copy;2019, Guilhem Marion.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 1.8.4</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.12</a>
      
    </div>

    

    
  </body>
</html>